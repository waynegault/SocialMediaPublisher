# =============================================================================
# Social Media Publisher - Example Environment Configuration
# Copy to .env and fill in your values.
# =============================================================================

# --- API KEYS ---
GEMINI_API_KEY=your_gemini_key
OPENAI_API_KEY=your_openai_key
HUGGINGFACE_API_KEY=your_huggingface_key
# Skip HuggingFace (token lacks Inference permissions), use Imagen instead
HF_PREFER_IF_CONFIGURED=False

# LinkedIn Credentials (developer.linkedin.com)
linkedin_username=
linkedin_password=
LINKEDIN_AUTHOR_URN=
LINKEDIN_ORGANIZATION_URN=
LINKEDIN_ACCESS_TOKEN=
LINKEDIN_CLIENT_ID=
LINKEDIN_CLIENT_ID_SECRET=
LINKEDIN_REDIRECT_URI=https://www.linkedin.com/developers/tools/oauth/redirect
LINKEDIN_LI_AT=
LINKEDIN_JSESSIONID=

# --- LINKEDIN SEARCH & CONNECTION MASTER SWITCH ---
# WARNING: LinkedIn actively detects automation and may restrict or ban accounts.
# Set to true ONLY if you accept the risk of account restrictions.
# When false (default), all LinkedIn profile searching and connection requests are disabled.
LINKEDIN_SEARCH_ENABLED=false

# --- PROFESSIONAL DISCIPLINE ---
# Your professional discipline (e.g., "chemical engineer", "software developer", "data scientist")
# This is used in prompts and content generation to personalize the output
DISCIPLINE=chemical engineer

# --- LOCAL LLM (LM Studio) ---
# Set to True to use a local LLM via LM Studio instead of cloud APIs
PREFER_LOCAL_LLM=False
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_MODEL=local-model

# --- GROQ API (Free Cloud LLM) ---
# Get free API key from: https://console.groq.com/keys
# Free tier: 30 requests/min, 14,400 requests/day
# When configured and PREFER_GROQ=True, Groq is used instead of Gemini for text generation
GROQ_API_KEY=
GROQ_MODEL=llama-3.3-70b-versatile
PREFER_GROQ=False

# --- SEARCH SETTINGS ---
# Search engine for LinkedIn profile lookups (google, bing, duckduckgo)
# DuckDuckGo is recommended - privacy-friendly and less likely to block
SEARCH_ENGINE=duckduckgo
# Browser automation backend: "uc" (undetected-chromedriver) or "nodriver" (recommended)
# nodriver is the successor to undetected-chromedriver with better anti-detection
BROWSER_BACKEND=nodriver
SEARCH_LOOKBACK_DAYS=7
# If TRUE, ignores lookback days and uses the timestamp of the last successful run
USE_LAST_CHECKED_DATE=True
# How often to run search cycles (in hours)
SEARCH_CYCLE_HOURS=24
# Maximum number of stories to request per search
MAX_STORIES_PER_SEARCH=1
# Maximum people to search for LinkedIn profiles per story (reduces API calls)
MAX_PEOPLE_PER_STORY=3

# --- CONTENT SETTINGS ---
# Target word count for story summaries (longer = more detailed posts)
SUMMARY_WORD_COUNT=200
# Minimum quality score to generate images (1-10, higher = stricter)
MIN_QUALITY_SCORE=8

# --- DEDUPLICATION SETTINGS ---
# Jaccard similarity threshold for semantic deduplication (0.0 to 1.0)
# Higher values = stricter matching (fewer false duplicates)
DEDUP_SIMILARITY_THRESHOLD=0.7

# --- LINKEDIN PROFILE REQUIREMENT ---
# When True, stories must have identified people with LinkedIn profiles to pass verification
# When False, stories can pass verification based on content quality alone
REQUIRE_LINKEDIN_PROFILES=False
# Minimum profiles needed when REQUIRE_LINKEDIN_PROFILES=True (default: 1)
MIN_LINKEDIN_PROFILES=1

# --- URL VALIDATION SETTINGS ---
# Enable URL validation before saving stories
VALIDATE_SOURCE_URLS=True

# --- API RETRY SETTINGS ---
# Number of retry attempts for transient API failures
API_RETRY_COUNT=3
# Base delay in seconds between retries (doubles each attempt)
API_RETRY_DELAY=1.0

# --- PUBLICATION SETTINGS ---
# How many stories to publish per cycle
STORIES_PER_CYCLE=3
# The total window to spread the stories over (in hours)
PUBLISH_WINDOW_HOURS=24
# Allow posting time to vary by +/- this many minutes
JITTER_MINUTES=30
# Start publishing between these hours (0-23)
PUBLISH_START_HOUR=8
PUBLISH_END_HOUR=20
# How often to check for due publications (in seconds)
PUBLISHER_CHECK_INTERVAL_SECONDS=600

# --- CLEANUP SETTINGS ---
# Clean up old unused stories after this many days
EXCLUSION_PERIOD_DAYS=30

# --- Promotion Message ---
# Details to be included in promotion messages
SIGNATURE_BLOCK_DETAIL=MEng Chemical and Process Engineering

# --- STORAGE SETTINGS ---
# Database file name
DB_NAME=content_engine.db
# Directory for generated images
IMAGE_DIR=generated_images

# --- IMAGE GENERATION SETTINGS ---
# Control human presence in generated images
# YES/True = Include central human character
# NO/False = No central character; random humans only if incidental/peripheral
HUMAN_IN_IMAGE=False

# --- EXTENSIBLE IMAGE PROVIDER (switch providers via .env) ---
# Supported providers: cloudflare, ai_horde, pollinations, huggingface
# Default is 'pollinations' - completely free, no API key required
IMAGE_PROVIDER=pollinations
IMAGE_MODEL=flux-realism
IMAGE_SIZE=1024x1024
IMAGE_TIMEOUT_SECONDS=120

# --- FREE PROVIDERS (no API key required) ---

# Pollinations.AI - completely free, no signup (default)
# Models: flux-realism, flux, turbo

# AI Horde (community-run, truly free, queue-based - may be slower)
# Models: SDXL 1.0, Deliberate, Anything
# AI_HORDE_API_KEY=0000000000

# HuggingFace - free tier (may have quota limits)
# Models: black-forest-labs/FLUX.1-schnell
# HUGGINGFACE_API_TOKEN=optional

# Cloudflare Workers AI (generous free tier ~10k images/day)
# CLOUDFLARE_ACCOUNT_ID=your_account_id
# CLOUDFLARE_API_TOKEN=your_api_token

# RapidAPI Key for Fresh LinkedIn Profile Data API
# Subscribe at: https://rapidapi.com/freshdata-freshdata-default/api/fresh-linkedin-profile-data/pricing
RAPIDAPI_KEY=
